{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from utils import load_processed_data, cv, get_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat, ind_station_mapper, speed_df = load_processed_data('../data/processed/rdp_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/env.yaml') as f:\n",
    "    ENV = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose Station**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_speed = speed_df[ENV['station_id']]\n",
    "station_speed = station_speed[station_speed.index.month.isin([5, 6, 7])] # subset and choose data in may-july\n",
    "station_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=station_speed.index, y=station_speed, title='Time Series Plot')\n",
    "fig.update_xaxes(title='Time')\n",
    "fig.update_yaxes(title='Speed (mph)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train-test data\n",
    "cutoff = station_speed[(station_speed.index.month == 5) | (station_speed.index.month == 6)].index.shape[0]\n",
    "train = station_speed.iloc[:cutoff]\n",
    "test = station_speed.iloc[cutoff:]\n",
    "\n",
    "# get normalization params from train\n",
    "train_mean = np.mean(train)\n",
    "train_std = np.std(train)\n",
    "train = (train - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train, test):\n",
    "        # Store the raw data.\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "        \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(data=data, targets=None, \n",
    "                                                          sequence_length=self.total_window_size, \n",
    "                                                          sequence_stride=1, shuffle=False, batch_size=1)\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    \n",
    "    def get_train(self):\n",
    "        return self.make_dataset(self.train.to_frame())\n",
    "\n",
    "    def get_test(self):\n",
    "        return self.make_dataset(self.test.to_frame())\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lags = ENV['num_lags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_for_mod(num_lags):\n",
    "    window = WindowGenerator(train=train, test=test, input_width=num_lags, # initialize sliding window \n",
    "                              label_width=1, shift=1)\n",
    "    \n",
    "    mod_train = window.get_train()\n",
    "    mod_test = window.get_test()\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for X, y in mod_train:\n",
    "        X_train.append(X[0, :, :])\n",
    "        y_train.append(y[0, :, :])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for X, y in mod_test:\n",
    "        X_test.append(X[0, :, :])\n",
    "        y_test.append(y[0, :, :])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_train_test_for_mod(num_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense\n",
    "import keras\n",
    "from time import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the CNN\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=(num_lags,), activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "start = time()\n",
    "model.fit(X_train, y_train, epochs=ENV['dl_train_epochs'], batch_size=1)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./trained/CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(columns=['mean_fit_time', 'param_num_lags', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'])\n",
    "for num_lags in [1, 3, 5, 10]:\n",
    "    metrics = {'mean_fit_time': 0, 'param_num_lags': num_lags, 'split0_test_score': 0, 'split1_test_score': 0, \n",
    "              'split2_test_score': 0, 'split3_test_score': 0, 'split4_test_score': 0}\n",
    "    X_train_cv, y_train_cv, X_test_cv, y_test_cv = get_train_test_for_mod(num_lags)\n",
    "    \n",
    "    for i in range(5): # 5 fold CV\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=32, kernel_size=(num_lags,), activation='relu'))\n",
    "        model.add(Dense(units=32, activation='relu'))\n",
    "        model.add(Dense(units=1))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        start = time()\n",
    "        model.fit(X_train_cv, y_train_cv, epochs=ENV['dl_train_epochs'], batch_size=1)\n",
    "        end = time()\n",
    "        \n",
    "        test_cv_preds = model.predict(X_test_cv)\n",
    "\n",
    "        # invert predictions\n",
    "        test_cv_preds = test_cv_preds * train_std + train_mean\n",
    "        \n",
    "        metrics['mean_fit_time'] += (end - start) / 5\n",
    "        metrics[f'split{i}_test_score'] = mean_squared_error(y_test_cv, test_cv_preds, squared=False)\n",
    "    cv_results = cv_results.append(metrics, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_row = cv_results.iloc[cv_results[[col for col in cv_results if 'split' in col]].mean(axis=1).idxmin()]\n",
    "best_params = best_results_row[[col for col in best_results_row.index if 'param' in col]].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./trained/CNN/grid_search_CNN.dat', 'wb') as f:\n",
    "#     pickle.dump({'best_params': best_params, 'results': cv_results}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=(best_params['num_lags'],), activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_train_test_for_mod(best_params['num_lags'])\n",
    "model.fit(X_train, y_train, epochs=ENV['dl_train_epochs'], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./trained/CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# invert predictions\n",
    "train_preds = train_preds * train_std + train_mean\n",
    "test_preds = test_preds * train_std + train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Line(x=station_speed.index, y=station_speed, name='True Values'))\n",
    "fig.add_trace(go.Line(x=station_speed[num_lags:cutoff].index, y=train_preds.flatten(), name='Predicted Values (Train)'))\n",
    "fig.add_trace(go.Line(x=station_speed[(cutoff+num_lags):].index, y=test_preds.flatten(), name='Predicted Values (Test)'))\n",
    "fig.update_layout(\n",
    "    title=\"CNN Forecast Results\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.write_html('../plots/CNN.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_metrics = cv(model, [X_train, y_train], metrics=['mse', 'mae', 'rmse', 'r2'], epochs=ENV['dl_cv_epochs'], verbose=True, folds=ENV['cv_folds'])\n",
    "\n",
    "# unscale test labels\n",
    "y_test = y_test * train_std + train_mean\n",
    "test_metrics = get_test_metrics(y_test.flatten(), test_preds.flatten())\n",
    "\n",
    "metrics = {'cv': cv_metrics, 'test': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./trained/CNN/metrics_CNN.dat', 'wb') as f:\n",
    "#     pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
