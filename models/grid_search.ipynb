{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from utils import load_processed_data, cv, get_test_metrics\n",
    "\n",
    "adj_mat, ind_station_mapper, speed_df = load_processed_data('../data/processed/rdp_ds')\n",
    "\n",
    "with open('../models/env.yaml') as f:\n",
    "    ENV = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "station_speed = speed_df[ENV['station_id']]\n",
    "station_speed = station_speed[station_speed.index.month.isin([5, 6, 7])] # subset and choose data in may-july"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train, test):\n",
    "        # Store the raw data.\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "        \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(data=data, targets=None, \n",
    "                                                          sequence_length=self.total_window_size, \n",
    "                                                          sequence_stride=1, shuffle=False, batch_size=1)\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    \n",
    "    def get_train(self):\n",
    "        return self.make_dataset(self.train.to_frame())\n",
    "\n",
    "    def get_test(self):\n",
    "        return self.make_dataset(self.test.to_frame())\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sliding window\n",
    "num_lags = ENV['num_lags']\n",
    "window = WindowGenerator(train=train, test=test, input_width=num_lags, \n",
    "                              label_width=1, shift=1)\n",
    "\n",
    "mod_train = window.get_train()\n",
    "mod_test = window.get_test()\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for X, y in mod_train:\n",
    "    X_train.append(X[0, :, :])\n",
    "    y_train.append(y[0, :, :])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "aman_path_to_capstone_dir = 'drive/MyDrive/School/Undergrad/Spring 2022/Capstone/Models/' \n",
    "os.chdir(f'{aman_path_to_capstone_dir}STGCN Training/models')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "!pip3 install prophet\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/School/Undergrad/Spring 2022/Capstone/Models/STGCN Training/utils/')\n",
    "from utils import load_processed_data\n",
    "\n",
    "adj_mat, ind_station_mapper, speeds = load_processed_data('../data/processed/fwy_405_n_ds')\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open('../models/env.yaml') as f:\n",
    "    ENV = yaml.load(f, Loader=yaml.Loader)\n",
    "    \n",
    "# subset and choose data in may-july\n",
    "speeds = speeds[speeds.index.month.isin([5, 6, 7])] \n",
    "\n",
    "# write to file\n",
    "outfile = '../data/processed/fwy_405_n_ds/speeds_form.csv'\n",
    "speeds.to_csv(outfile, index=False, header=False)\n",
    "\n",
    "# write to file\n",
    "outfile = '../data/processed/fwy_405_n_ds/adj_mat_form.csv'\n",
    "pd.DataFrame(adj_mat).to_csv(outfile, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', \n",
    "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "grid_values = {'n_lags':[1,3,5,10]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=grid_values, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search STGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', \n",
    "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "grid_values = {'k':[3, 5, 8, 10, 12], 'epochs':[5, 10, 20, 30]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=grid_values, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
