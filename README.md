# DS Capstone

## Data Loading
1. Create a new environment and install the dependencies in requirements.txt.
2. Open the utils directory and read the README to set up credentials to scrape from PEMS.
3. Run data_loader.py to gather the datasets.
4. Run the cells in station_meta_extractor.ipynb and station_data_extractor.ipynb to process and load data into pickle files used in EDA.
5. Run eda.ipynb to get an overview of the data.
6. Run data_preparation.ipynb to process the data for model building. The output pickle files will be in ./data/processed.
